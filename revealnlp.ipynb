{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ty-ex9W5jE4",
        "outputId": "b9d80b3c-0275-4694-c4d9-a68c4b0f0556"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   category     term   frequency\n",
            "0         0      app  189.611081\n",
            "1         1    tasks   58.099738\n",
            "2         2     work   48.774678\n",
            "3         3     good   37.940386\n",
            "4         4  version   69.153458\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download necessary files from NLTK:\n",
        "# punkt -> Tokenization\n",
        "# stopwords -> Stop words removal\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "# Load the reviews dataset and preview it\n",
        "reviews = pd.read_csv(\"reviews.csv\")\n",
        "reviews.head()\n",
        "\n",
        "# Step 1: Preprocess the negative reviews\n",
        "\n",
        "# Filter negative reviews (having a score of 1 or 2)\n",
        "negative_reviews_tmp = reviews[(reviews[\"score\"] == 1) | (reviews[\"score\"] == 2)][\"content\"]\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Performs all the required steps in the text preprocessing\"\"\"\n",
        "\n",
        "    # Tokenizing the text\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Removing stop words and non-alpha characters\n",
        "    filtered_tokens = [\n",
        "        token\n",
        "        for token in tokens\n",
        "        if token.isalpha() and token.lower() not in stopwords.words(\"english\")\n",
        "    ]\n",
        "\n",
        "    return \" \".join(filtered_tokens)\n",
        "\n",
        "\n",
        "# Apply the preprocessing function to the negative reviews\n",
        "negative_reviews_cleaned = negative_reviews_tmp.apply(preprocess_text)\n",
        "\n",
        "# Store the preprocessed negative reviews in a pandas DataFrame\n",
        "preprocessed_reviews = pd.DataFrame({\"review\": negative_reviews_cleaned})\n",
        "preprocessed_reviews.head()\n",
        "\n",
        "# Step 2: Vectorize the cleaned negative reviews using TF-IDF\n",
        "\n",
        "# Vectorize the cleaned reviews using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(preprocessed_reviews[\"review\"])\n",
        "\n",
        "# Step 3: Apply K-means clustering to tfidf_matrix\n",
        "\n",
        "# Apply K-means clustering (store the model as clust_kmeans)\n",
        "clust_kmeans = KMeans(n_clusters=5, random_state=500)\n",
        "pred_labels = clust_kmeans.fit_predict(tfidf_matrix)\n",
        "\n",
        "# Store the predicted labels in a list variable called categories\n",
        "categories = pred_labels.tolist()\n",
        "preprocessed_reviews[\"category\"] = categories\n",
        "\n",
        "# Step 4: For each unique cluster label, find the most frequent term\n",
        "\n",
        "# Get the feature names (terms) from the vectorizer\n",
        "terms = vectorizer.get_feature_names_out()\n",
        "\n",
        "# List to save the top term for each cluster\n",
        "topic_terms_list = []\n",
        "\n",
        "for cluster in range(clust_kmeans.n_clusters):\n",
        "    # Get indices of reviews in the current cluster\n",
        "    cluster_indices = [i for i, label in enumerate(categories) if label == cluster]\n",
        "\n",
        "    # Sum the tf-idf scores for each term in the cluster\n",
        "    cluster_tfidf_sum = tfidf_matrix[cluster_indices].sum(axis=0)\n",
        "    cluster_term_freq = np.asarray(cluster_tfidf_sum).ravel()\n",
        "\n",
        "    # Get the top term and its frequencies\n",
        "    top_term_index = cluster_term_freq.argsort()[::-1][0]\n",
        "\n",
        "    # Append rows to the topic_terms DataFrame with three fields:\n",
        "    # - category: label / cluster assigned from K-means\n",
        "    # - term: the identified top term\n",
        "    # - frequency: term's weight for the category\n",
        "    topic_terms_list.append(\n",
        "        {\n",
        "            \"category\": cluster,\n",
        "            \"term\": terms[top_term_index],\n",
        "            \"frequency\": cluster_term_freq[top_term_index],\n",
        "        }\n",
        "    )\n",
        "\n",
        "# Pandas DataFrame to store results from this step\n",
        "topic_terms = pd.DataFrame(topic_terms_list)\n",
        "\n",
        "# Output the final result\n",
        "print(topic_terms)\n"
      ]
    }
  ]
}